# 15.1. Informatique

## Introduction : l’informatique comme mathématiques exécutées

L’informatique moderne est souvent décrite comme de la **mathématique mise en mouvement** :  
des algorithmes (procédures abstraites) sont traduits en programmes et exécutés par des machines.  
Les choix d’algorithmes, de structures de données et d’architectures reposent sur des notions
mathématiques profondes : complexité, théorie des graphes, logique, théorie de l’information, etc.

Dans ce chapitre, nous explorons comment les mathématiques structurent l’informatique à trois niveaux :
les **algorithmes**, la **théorie de l’information** et le **calcul distribué**.

## Algorithmes et complexité

### Problèmes, algorithmes, complexité

Un **algorithme** est une procédure finie qui résout un problème bien défini.
Deux questions fondamentales se posent :

1. **Décidabilité** : existe-t-il un algorithme qui résout ce problème pour toutes les instances ?  
2. **Complexité** : si oui, combien de ressources (temps, mémoire) sont nécessaires ?

La théorie de la complexité classe les problèmes en grandes familles :

- **P** : problèmes résolubles en temps polynomial (efficace)  
- **NP** : problèmes dont une solution proposée peut être vérifiée en temps polynomial  
- **NP-complets** : les plus difficiles de NP (si l’un est en P, alors P = NP)  
- **NP-difficiles** : au moins aussi difficiles que les NP-complets (pas forcément dans NP)

La question **P vs NP** — savoir si tout problème dont la solution est vérifiable rapidement
est aussi résoluble rapidement — est l’un des grands problèmes ouverts des mathématiques.

### Algorithmes exacts, approximatifs, randomisés

- **Algorithmes exacts** : trouvent toujours une solution optimale (ex. Dijkstra pour les plus courts chemins
  avec poids positifs).
- **Algorithmes d’approximation** : garantissent une solution proche de l’optimum avec un **ratio d’approximation**
  (ex. 3/2 pour certains TSP métriques).
- **Algorithmes randomisés** : utilisent le hasard (lancés de dés) pour accélérer la résolution
  ou simplifier les preuves (ex. Quicksort, Monte Carlo, Las Vegas).

Les mathématiques (probabilités, inégalités de concentration, combinatoire) permettent de démontrer
des bornes de performance précises : temps moyen, variance, probabilité d’erreur, etc.

### Structures de données

L’efficacité d’un algorithme dépend aussi des **structures de données** :

- **Listes, tableaux, piles, files** : opérations O(1) ou O(n) selon le cas  
- **Arbres équilibrés** (AVL, rouge-noir) : insertion/recherche en O(log n)  
- **Tables de hachage** : recherche moyenne en O(1), mais analyse probabiliste fine  
- **Graphes** : représentations par listes d’adjacence ou matrices, au cœur des réseaux

La conception et l’analyse de ces structures sont profondément mathématiques (invariants, ordres,
probabilités, amortissement, etc.).

## Théorie de l’information et codage

### Entropie et quantité d’information

La **théorie de l’information** de Shannon quantifie la quantité moyenne d’information d’une source :

\[
H(X) = -\sum_x p(x) \log_2 p(x)
\]

- Plus une source est imprévisible, plus son entropie est élevée.  
- L’entropie donne une **borne inférieure** sur la longueur moyenne minimale de tout code sans perte.

### Codage de source (compression)

- **Codage de Huffman** : arbre binaire optimal pour symboles indépendants, proche de l’entropie.  
- **Codage arithmétique** : approche asymptotiquement optimale, très utilisé en audio/vidéo.  
- **Compression moderne** : mélanges de dictionnaire (LZ77, LZW), Huffman, modèles statistiques.

### Correction d’erreurs

Dans tout canal bruité (fibre optique, Wi-Fi, stockage), des erreurs apparaissent.
Les **codes correcteurs d’erreurs** ajoutent une redondance contrôlée :

- **Reed-Solomon** : basés sur des polynômes sur des corps finis, très utilisés sur CD/DVD, QR codes.  
- **LDPC (Low-Density Parity-Check)** : matrices creuses, décodage itératif proche de la limite de Shannon.  
- **Turbo codes** : combinent plusieurs codes convolutifs avec décodage itératif.

Ces constructions s’appuient sur l’algèbre linéaire, la théorie des corps finis et la combinatoire.

### Cryptographie

La cryptographie moderne repose sur des problèmes mathématiques difficiles :

- **RSA** : difficulté de la factorisation de grands entiers.  
- **ECC (Elliptic Curve Cryptography)** : logarithme discret sur courbes elliptiques.  
- **Post-quantique** : cryptographie sur réseaux euclidiens (LWE, NTRU), codes, isogénies.

Là encore, l’informatique applique directement des résultats d’algèbre, de théorie des nombres,
de géométrie algébrique et de complexité.

## Calcul distribué et architectures modernes

### Modèles de calcul distribué

Dans un système distribué, plusieurs machines communiquent via un réseau :

- **Modèle synchrone / asynchrone** : délais de communication bornés ou non.  
- **Défaillances** : crash (pannes franches) ou byzantines (comportement arbitraire).  
- **Consistance** : assurer que tous voient un état cohérent (par ex. dans une base de données distribuée).

Des théorèmes comme **FLP** montrent qu’en présence de pannes et d’asynchronisme parfait,
certains objectifs (consensus déterministe) sont impossibles à atteindre.  
Les protocoles pratiques (Paxos, Raft) sont donc des compromis entre hypothèses et garanties.

### Consensus et tolérance aux fautes

- **Consensus** : tous les nœuds honnêtes doivent décider la même valeur.  
- **Tolérance aux fautes byzantines** : certains nœuds peuvent mentir ou être corrompus.  
- **Algorithmes BFT** (Byzantine Fault Tolerant) : PBFT, HotStuff, etc., utilisés dans certaines blockchains.

Ces problèmes se modélisent par des graphes, des systèmes dynamiques discrets
et des arguments combinatoires/probabilistes.

### Cloud, microservices et big data

Les architectures modernes s’appuient massivement sur :

- **Cloud computing** : mutualisation de ressources (AWS, Azure, GCP).  
- **Microservices** : décomposition d’un système en services indépendants communiquant par API.  
- **Frameworks big data** : MapReduce, Spark, Flink, qui reposent sur des modèles algébriques
  (agrégations associatives, monades, etc.).

L’optimisation de ces systèmes (ordonnancement, allocation de ressources, tolérance aux pannes)
est un problème mathématique d’optimisation combinatoire et stochastique de grande taille.

## Conclusion : l’informatique comme laboratoire des mathématiques appliquées

L’informatique illustre de manière spectaculaire la puissance des mathématiques :
des concepts a priori très abstraits (complexité, entropie, corps finis, graphes, logique)
deviennent des briques concrètes de nos systèmes numériques.

Comprendre ces fondations mathématiques permet non seulement d’écrire du code qui marche,
mais surtout de concevoir des systèmes **fiables, efficaces, sécurisés et évolutifs** —
condition indispensable dans un monde où le numérique gouverne de plus en plus nos vies.

# 6.5. Applications : Machine Learning, Médecine, Économie

## Introduction

Les probabilités et statistiques ne sont pas de simples outils théoriques : elles constituent le socle opérationnel de nombreuses disciplines appliquées. Ce chapitre explore trois domaines majeurs où ces méthodes transforment la pratique : l'apprentissage automatique, la médecine et l'économie.

---

## 1. Machine Learning : l'apprentissage par les données

### 1.1 Apprentissage supervisé

L'apprentissage supervisé consiste à apprendre une fonction f : X → Y à partir d'exemples étiquetés.

#### Régression
- **Objectif** : prédire une valeur continue (prix, température, durée)
- **Modèles** : régression linéaire, polynomiale, ridge, lasso
- **Métrique** : MSE = (1/n) Σᵢ (yᵢ - ŷᵢ)²

#### Classification
- **Objectif** : assigner une catégorie (spam/non-spam, diagnostic)
- **Modèles** : régression logistique, SVM, arbres de décision, k-NN
- **Métriques** : précision, rappel, F1-score, AUC-ROC

#### Validation et généralisation
- **Validation croisée** : k-fold pour estimer la performance réelle
- **Courbe d'apprentissage** : diagnostic de sur/sous-apprentissage
- **Régularisation** : L1 (lasso), L2 (ridge) pour éviter l'overfitting

### 1.2 Apprentissage non supervisé

Découvrir des structures cachées sans étiquettes.

#### Clustering (partitionnement)
- **K-means** : minimise la variance intra-cluster
- **DBSCAN** : détecte des clusters de forme arbitraire
- **Clustering hiérarchique** : dendrogramme de similarités

#### Réduction de dimensionnalité
- **PCA** : projette sur les axes de variance maximale
- **t-SNE** : préserve les voisinages locaux (visualisation)
- **UMAP** : compromis entre structure locale et globale

#### Détection d'anomalies
- **Isolation Forest** : isole les points atypiques
- **One-class SVM** : frontière autour des données normales
- **Autoencodeurs** : erreur de reconstruction élevée = anomalie

### 1.3 Fondements théoriques

#### Théorie PAC (Probably Approximately Correct)
- **Définition** : un algorithme est PAC-learnable si, avec probabilité ≥ 1-δ, il trouve une hypothèse d'erreur ≤ ε
- **Complexité d'échantillon** : nombre d'exemples nécessaires
- **Dimension VC** : mesure la capacité d'une classe d'hypothèses

#### Compromis biais-variance
- **Biais** : erreur due aux hypothèses simplificatrices du modèle
- **Variance** : sensibilité aux fluctuations des données d'entraînement
- **Erreur totale** : Erreur = Biais² + Variance + Bruit irréductible

---

## 2. Médecine : des statistiques qui sauvent des vies

### 2.1 Essais cliniques

Les essais cliniques randomisés (ECR) sont l'étalon-or pour évaluer les traitements.

#### Conception
- **Randomisation** : affectation aléatoire pour éliminer les biais de sélection
- **Double aveugle** : ni patient ni médecin ne connaît le groupe
- **Groupe contrôle** : placebo ou traitement standard

#### Analyse statistique
- **Intention de traiter (ITT)** : analyse tous les patients selon leur groupe initial
- **Per-protocole** : analyse uniquement ceux qui ont suivi le protocole
- **Taille d'effet** : différence cliniquement significative (Cohen's d)

#### Puissance statistique
- **Puissance** : probabilité de détecter un effet réel (typiquement 80%)
- **Taille d'échantillon** : calculée avant l'étude
- **Erreur de type I (α)** : faux positif (typiquement 5%)
- **Erreur de type II (β)** : faux négatif (1 - puissance)

### 2.2 Épidémiologie

Étude de la distribution et des déterminants des maladies dans les populations.

#### Mesures d'association
- **Risque relatif (RR)** : P(maladie|exposé) / P(maladie|non-exposé)
- **Odds ratio (OR)** : approximation du RR pour les maladies rares
- **Risque attribuable** : proportion de cas dus à l'exposition

#### Types d'études
- **Cohorte** : suit des exposés et non-exposés dans le temps
- **Cas-témoins** : compare des malades et des sains rétrospectivement
- **Transversale** : photographie à un instant donné

#### Modèles de survie
- **Kaplan-Meier** : estimation non-paramétrique de la survie
- **Modèle de Cox** : régression sur le risque instantané (hazard ratio)
- **Censure** : gestion des observations incomplètes

### 2.3 Diagnostic médical

#### Performance des tests
- **Sensibilité** : P(test+|malade) — détecte les vrais malades
- **Spécificité** : P(test-|sain) — identifie les vrais sains
- **VPP/VPN** : valeurs prédictives positive et négative

#### Courbe ROC
- **Construction** : sensibilité vs (1-spécificité) pour différents seuils
- **AUC** : aire sous la courbe (0.5 = hasard, 1 = parfait)
- **Choix du seuil** : compromis selon le contexte clinique

#### Tests multiples
- **Problème** : avec 20 tests à α=5%, on attend 1 faux positif
- **Correction de Bonferroni** : α' = α/n (conservateur)
- **Contrôle du FDR** : procédure de Benjamini-Hochberg

---

## 3. Économie : quantifier l'incertain

### 3.1 Économétrie

L'économétrie applique les méthodes statistiques aux données économiques.

#### Modèles linéaires
- **Régression OLS** : y = Xβ + ε, minimise les moindres carrés
- **Hypothèses de Gauss-Markov** : conditions pour l'optimalité de l'OLS
- **Tests de significativité** : t-test sur les coefficients

#### Problèmes courants
- **Hétéroscédasticité** : variance non constante des erreurs
- **Autocorrélation** : erreurs corrélées dans le temps
- **Endogénéité** : corrélation entre régresseurs et erreurs

#### Solutions
- **Écarts-types robustes** : White, Newey-West
- **Variables instrumentales** : 2SLS pour l'endogénéité
- **Modèles à effets fixes/aléatoires** : données de panel

### 3.2 Finance quantitative

#### Modèles de prix d'actifs
- **CAPM** : E[Rᵢ] = Rf + βᵢ(E[Rm] - Rf)
- **Modèles multi-facteurs** : Fama-French (taille, value, momentum)
- **APT** : Arbitrage Pricing Theory

#### Séries temporelles financières
- **Stationnarité** : test de Dickey-Fuller (racine unitaire)
- **ARIMA** : modélisation de séries non-stationnaires
- **GARCH** : modélisation de la volatilité conditionnelle

#### Gestion des risques
- **VaR** : Value at Risk (perte maximale à un niveau de confiance)
- **Expected Shortfall** : perte moyenne au-delà de la VaR
- **Stress testing** : scénarios extrêmes

### 3.3 Macroéconomie

#### Modèles vectoriels
- **VAR** : vecteurs autorégressifs pour plusieurs variables
- **SVAR** : VAR structurels avec restrictions économiques
- **Fonctions de réponse impulsionnelle** : effet d'un choc

#### Relations de long terme
- **Cointégration** : variables non-stationnaires avec relation stable
- **Test de Johansen** : nombre de relations de cointégration
- **Modèles à correction d'erreur** : dynamique court/long terme

#### Modèles d'équilibre
- **DSGE** : Dynamic Stochastic General Equilibrium
- **Calibration** : paramètres fixés selon la littérature
- **Estimation bayésienne** : combine prior et données

---

## 4. Convergences et synergies

### 4.1 Machine Learning en médecine

- **Imagerie médicale** : CNN pour la détection de tumeurs
- **Prédiction de risque** : modèles de survie avec ML
- **Médecine personnalisée** : traitement adapté au profil génétique

### 4.2 Machine Learning en finance

- **Trading algorithmique** : prédiction de prix, arbitrage
- **Scoring crédit** : évaluation du risque de défaut
- **Détection de fraude** : anomalies dans les transactions

### 4.3 Défis communs

- **Interprétabilité** : comprendre les décisions des modèles
- **Biais** : données non représentatives, discrimination
- **Causalité vs corrélation** : ML excelle en prédiction, moins en causalité

---

## Conclusion

Les probabilités et statistiques irriguent les applications les plus critiques de notre société. Du diagnostic médical aux décisions économiques, en passant par les systèmes d'apprentissage automatique, ces outils mathématiques permettent de :

1. **Quantifier l'incertitude** inhérente aux phénomènes complexes
2. **Prendre des décisions** rationnelles face à des données imparfaites
3. **Valider scientifiquement** les hypothèses et les traitements

La maîtrise de ces méthodes est devenue indispensable pour tout professionnel confronté à des données et des décisions sous incertitude.

# 8.3. Applications : IA, Communication, Neurosciences

## Introduction

La théorie de l'information transcende son domaine d'origine — les télécommunications — pour irriguer l'intelligence artificielle, les réseaux modernes et même notre compréhension du cerveau. Ce chapitre explore ces applications fascinantes où l'entropie et l'information mutuelle éclairent des phénomènes complexes.

---

## 1. Intelligence artificielle et machine learning

### 1.1 Fonctions de perte informationnelles

#### Entropie croisée (Cross-Entropy Loss)

La fonction de perte standard pour la classification :
```
L = -Σᵢ yᵢ log(ŷᵢ)
```
où y est la distribution cible (one-hot) et ŷ les probabilités prédites.

**Interprétation** : coût moyen en bits pour encoder les vraies classes avec le modèle appris.

**Propriétés** :
- Minimiser L équivaut à minimiser D_KL(y || ŷ)
- Gradient simple : ∂L/∂ŷᵢ = -yᵢ/ŷᵢ
- Combiné avec softmax : gradient = ŷ - y

#### Entropie binaire
Pour la classification binaire :
```
L = -[y log(ŷ) + (1-y) log(1-ŷ)]
```

### 1.2 Arbres de décision et gain d'information

#### Critère de sélection
À chaque nœud, choisir l'attribut maximisant le **gain d'information** :
```
Gain(S, A) = H(S) - Σᵥ (|Sᵥ|/|S|) H(Sᵥ)
```
où Sᵥ sont les sous-ensembles après division selon l'attribut A.

**Algorithmes** :
- **ID3** : gain d'information pur
- **C4.5** : ratio de gain (normalise par l'entropie de la division)
- **CART** : impureté de Gini (approximation de l'entropie)

#### Impureté de Gini
```
Gini(S) = 1 - Σᵢ pᵢ²
```
Approximation de l'entropie, plus rapide à calculer.

### 1.3 Information mutuelle en deep learning

#### Information Bottleneck
Théorie de Tishby : un bon réseau compresse l'entrée X tout en préservant l'information sur Y.
```
max I(Z; Y) - β I(Z; X)
```
où Z est la représentation interne.

**Interprétation** :
- Phase d'ajustement : I(Z; Y) augmente
- Phase de compression : I(Z; X) diminue

#### Estimation de l'information mutuelle
- **MINE** (Mutual Information Neural Estimation)
- **InfoNCE** (Noise Contrastive Estimation)
- Utilisés dans l'apprentissage contrastif (SimCLR, MoCo)

### 1.4 Modèles génératifs

#### VAE (Variational Autoencoder)
Objectif (ELBO) :
```
L = E[log p(x|z)] - D_KL(q(z|x) || p(z))
```
- Premier terme : reconstruction
- Second terme : régularisation vers le prior (entropie)

#### Diffusion Models
- Processus de diffusion : ajout graduel de bruit (augmente l'entropie)
- Processus inverse : débruitage (réduit l'entropie)
- Score matching : apprend le gradient de log-densité

### 1.5 Régularisation entropique

#### Label smoothing
Remplace les one-hot par une distribution légèrement uniforme :
```
y' = (1-ε)y + ε/K
```
Augmente l'entropie des cibles, améliore la généralisation.

#### Entropy regularization en RL
Encourage l'exploration en ajoutant un bonus d'entropie à la récompense :
```
J = E[Σₜ rₜ + α H(π(·|sₜ))]
```
Utilisé dans SAC (Soft Actor-Critic), A3C.

#### Maximum Entropy RL
Politique optimale : maximise la récompense ET l'entropie.
Produit des comportements plus robustes et exploratoires.

---

## 2. Communications modernes

### 2.1 Capacité des canaux réels

#### Canal AWGN (Additive White Gaussian Noise)
```
C = B log₂(1 + SNR) bits/seconde
```
où B est la bande passante.

**Formule de Shannon-Hartley** : limite fondamentale de tout système de communication.

#### Canaux à évanouissement (fading)
- **Rayleigh** : pas de ligne directe
- **Rician** : ligne directe + réflexions
- Capacité ergodique : moyenne sur les réalisations du canal

### 2.2 MIMO et théorie de l'information

#### Capacité MIMO
Pour nₜ antennes d'émission et nᵣ de réception :
```
C = log₂ det(I + (SNR/nₜ) HH†)
```
où H est la matrice de canal.

**Gain** : la capacité croît linéairement avec min(nₜ, nᵣ) !

#### Massive MIMO
- Centaines d'antennes à la station de base
- Focalisation spatiale (beamforming)
- Multiplication de la capacité

### 2.3 Codage réseau (Network Coding)

#### Principe
Au lieu de simplement router, les nœuds combinent les paquets :
```
Nœud intermédiaire : envoie a ⊕ b au lieu de a puis b
```

#### Avantages
- Augmente le débit dans certaines topologies
- Améliore la robustesse aux pertes
- Théorème max-flow min-cut atteint pour le multicast

### 2.4 Sécurité informationnelle

#### Capacité de secret
```
Cₛ = max(C_AB - C_AE, 0)
```
où C_AB est la capacité Alice-Bob et C_AE la capacité Alice-Ève.

**Wiretap channel** : transmission secrète possible si le canal légitime est meilleur que celui de l'espion.

#### Physical layer security
- Exploite les différences de canaux
- Secret sans clé pré-partagée
- Complémentaire à la cryptographie

---

## 3. Neurosciences computationnelles

### 3.1 Codage neural

#### Le cerveau comme canal de communication
```
Stimulus → Encodage neural → Transmission → Décodage → Perception
```

#### Taux d'information
- Nerf optique : ~10⁶ bits/seconde
- Mais perception consciente : ~40 bits/seconde
- Compression massive !

### 3.2 Types de codage

#### Codage par taux (rate coding)
- Information dans la fréquence de décharge
- Moyenne temporelle des spikes
- Simple mais lent

#### Codage temporel (temporal coding)
- Information dans le timing précis des spikes
- Plus rapide, plus riche
- Exemples : localisation sonore, olfaction

#### Codage par population
- Information distribuée sur plusieurs neurones
- Robuste au bruit
- Décodage par moyenne pondérée

### 3.3 Information et perception

#### Efficient coding hypothesis (Barlow, 1961)
Le système sensoriel maximise l'information transmise sur le monde extérieur.

**Prédictions vérifiées** :
- Adaptation au contraste
- Champs récepteurs décorrélants
- Whitening des signaux

#### Predictive coding
Le cerveau maintient un modèle prédictif et ne transmet que les erreurs de prédiction.
```
Signal transmis = Observation - Prédiction
```
Minimise la redondance, maximise l'efficacité.

### 3.4 Mesures d'information en neurosciences

#### Information mutuelle stimulus-réponse
```
I(S; R) = H(R) - H(R|S)
```
Mesure combien la réponse neurale "dit" sur le stimulus.

#### Méthodes d'estimation
- **Direct** : histogrammes (problème de sous-échantillonnage)
- **Plugin** : correction de biais (Panzeri-Treves)
- **Bayésien** : prior sur les distributions

#### Transfer entropy
Mesure le flux d'information directionnel entre séries temporelles :
```
TE(X→Y) = I(Yₜ₊₁; Xₜ | Yₜ)
```
Détecte les connexions fonctionnelles.

### 3.5 Théorie de l'information intégrée (IIT)

#### Phi (Φ) : mesure de conscience
Tononi propose que la conscience correspond à l'information intégrée Φ :
- Information générée par le système entier
- Moins l'information des parties séparées

#### Implications
- Systèmes à haut Φ seraient conscients
- Explique pourquoi le cervelet (peu intégré) ne contribue pas à la conscience
- Controversé mais influent

### 3.6 Interface cerveau-machine

#### Décodage neural
- Enregistrement de l'activité (électrodes, ECoG)
- Décodage par ML : intention → commande
- Applications : prothèses, communication pour paralysés

#### Information mutuelle comme métrique
```
I(Intention; Signal_décodé)
```
Mesure la qualité du décodage.

#### Limites fondamentales
La capacité de l'interface est bornée par l'information mutuelle entre l'activité neurale et l'intention.

---

## 4. Convergences et frontières

### 4.1 Compression et intelligence

#### Principe de compression de Solomonoff
L'intelligence est liée à la capacité de compression :
- Trouver des régularités = comprendre
- Prédire = compresser le futur

#### Large Language Models
- Entraînés à prédire le token suivant
- Équivalent à compresser le texte
- Émergence de capacités générales

### 4.2 Thermodynamique de l'apprentissage

#### Coût énergétique de l'information
Principe de Landauer : effacer 1 bit coûte au minimum k_B T ln(2) joules.

#### Efficacité du cerveau
- ~20 watts pour ~10¹⁵ synapses
- ~10⁻¹⁵ joules par opération synaptique
- Proche de la limite de Landauer !

### 4.3 Information quantique et cerveau

#### Hypothèses spéculatives
- Penrose-Hameroff : conscience et effets quantiques
- Pas de consensus scientifique
- Décohérence trop rapide à température corporelle

---

## Conclusion

La théorie de l'information fournit un langage universel pour comprendre :

1. **L'apprentissage automatique** : fonctions de perte, compression des représentations, exploration
2. **Les communications** : limites fondamentales, codage optimal, sécurité
3. **Le cerveau** : codage neural, perception efficace, conscience

Ces applications illustrent la puissance unificatrice du concept d'information, qui transcende les frontières disciplinaires pour éclairer des phénomènes aussi divers que l'entraînement d'un réseau de neurones et le fonctionnement de notre propre esprit.

> "Information is the resolution of uncertainty." — Claude Shannon

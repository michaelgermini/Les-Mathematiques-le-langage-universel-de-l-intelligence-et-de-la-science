# 8.2. Codage, transmission et compression

## Introduction

La théorie de l'information de Shannon ne se limite pas à mesurer l'information : elle établit les limites fondamentales de ce qu'il est possible de faire avec cette information. Ce chapitre explore les trois piliers pratiques : le codage source (compression), le codage canal (transmission fiable) et leurs applications.

---

## 1. Codage source : la compression

### 1.1 Principe fondamental

Le **premier théorème de Shannon** établit que :
- Une source d'entropie H bits/symbole peut être compressée jusqu'à H bits/symbole
- Toute compression en dessous de H entraîne une perte d'information

### 1.2 Compression sans perte

#### Codage de Huffman
- **Principe** : codes plus courts pour les symboles fréquents
- **Optimalité** : atteint l'entropie pour des symboles indépendants
- **Limite** : au moins 1 bit par symbole

```
Exemple : "ABRACADABRA"
A: 5/11 → code "0"
B: 2/11 → code "10"  
R: 2/11 → code "110"
C: 1/11 → code "1110"
D: 1/11 → code "1111"

Original : 11 × 8 = 88 bits (ASCII)
Compressé : 5×1 + 2×2 + 2×3 + 1×4 + 1×4 = 23 bits
```

#### Codage arithmétique
- **Principe** : encode le message entier comme un intervalle dans [0,1)
- **Avantage** : peut descendre sous 1 bit/symbole
- **Utilisé dans** : JPEG 2000, H.264/H.265, compression moderne

#### Algorithme :
1. Initialiser l'intervalle [0, 1)
2. Pour chaque symbole, subdiviser proportionnellement aux probabilités
3. Sélectionner le sous-intervalle correspondant au symbole
4. Le code final est un nombre dans l'intervalle final

#### Codage par dictionnaire

**LZ77 (Lempel-Ziv 1977)**
- Référence des occurrences passées : (distance, longueur, prochain)
- Base de gzip, DEFLATE

**LZ78 / LZW**
- Construit un dictionnaire dynamiquement
- Utilisé dans GIF, compress

**DEFLATE**
- Combine LZ77 + Huffman
- Standard pour ZIP, PNG, HTTP compression

#### ANS (Asymmetric Numeral Systems)
- Alternative moderne au codage arithmétique
- Plus rapide, parallélisable
- Utilisé dans Zstandard (zstd), LZFSE

### 1.3 Compression avec perte

Accepte une dégradation contrôlée pour un meilleur taux de compression.

#### Théorie débit-distorsion
Shannon définit la fonction R(D) : débit minimal pour une distorsion D.
```
R(D) = min_{P(X̂|X): E[d(X,X̂)]≤D} I(X; X̂)
```

#### Transformées

| Transformée | Domaine | Usage |
|-------------|---------|-------|
| **DCT** | Fréquence (blocs) | JPEG, MPEG, H.264 |
| **DWT** | Fréquence (ondelettes) | JPEG 2000 |
| **FFT** | Fréquence | Audio |
| **KLT** | Décorrélation optimale | Théorique |

#### Quantification
- **Scalaire** : arrondi à un ensemble discret de valeurs
- **Vectorielle** : quantifie des groupes de valeurs ensemble
- **Adaptative** : ajuste la précision selon le contenu

### 1.4 Standards de compression

| Format | Type | Technique | Usage |
|--------|------|-----------|-------|
| **JPEG** | Image | DCT + quantification + Huffman | Photos |
| **PNG** | Image | DEFLATE (sans perte) | Graphiques |
| **WebP** | Image | Prédiction + transformée | Web |
| **MP3** | Audio | Psychoacoustique + MDCT | Musique |
| **AAC** | Audio | Meilleur que MP3 | Streaming |
| **H.264** | Vidéo | Prédiction inter/intra + DCT | Standard actuel |
| **H.265** | Vidéo | Meilleur que H.264 | 4K/8K |
| **AV1** | Vidéo | Open source, très efficace | YouTube, Netflix |

---

## 2. Codage canal : transmission fiable

### 2.1 Le problème du bruit

Un canal de communication introduit des erreurs :
```
Message → Encodeur → Canal bruyant → Décodeur → Message (avec erreurs?)
```

### 2.2 Deuxième théorème de Shannon

**Énoncé** : Pour tout canal de capacité C, il est possible de transmettre à un débit R < C avec une probabilité d'erreur arbitrairement faible.

**Capacité du canal binaire symétrique** (probabilité d'erreur p) :
```
C = 1 - H(p) = 1 + p log₂(p) + (1-p) log₂(1-p)
```

**Capacité du canal gaussien** (rapport signal/bruit SNR) :
```
C = (1/2) log₂(1 + SNR) bits/utilisation
```

### 2.3 Codes correcteurs d'erreurs

#### Codes linéaires
Un code linéaire [n, k, d] :
- **n** : longueur du mot de code
- **k** : dimension (bits d'information)
- **d** : distance minimale (détecte d-1 erreurs, corrige ⌊(d-1)/2⌋)

**Matrice génératrice G** : encode k bits en n bits
**Matrice de parité H** : vérifie la validité (syndrome)

#### Codes de Hamming [7,4,3]
- Corrige 1 erreur par bloc de 7 bits
- 4 bits d'information + 3 bits de parité
- Efficacité : 4/7 ≈ 57%

#### Codes de Reed-Solomon
- Codes sur des corps finis GF(2^m)
- Corrigent des rafales d'erreurs (burst errors)
- Utilisés dans : CD, DVD, QR codes, stockage

#### Codes convolutifs
- Mémoire : la sortie dépend des entrées passées
- Représentation en treillis (trellis)
- Décodage : algorithme de Viterbi (maximum de vraisemblance)

#### Turbo codes (1993)
- Deux encodeurs convolutifs en parallèle avec entrelacement
- Décodage itératif (échange de probabilités)
- Proche de la limite de Shannon
- Utilisés dans 3G/4G

#### Codes LDPC (Low-Density Parity-Check)
- Matrice de parité creuse (sparse)
- Décodage par propagation de croyances (belief propagation)
- Très proches de la capacité de Shannon
- Utilisés dans WiFi 802.11n/ac/ax, 5G, DVB-S2

#### Codes polaires (2009)
- Premier code prouvé atteindre la capacité
- Construction basée sur la polarisation des canaux
- Utilisés dans 5G (canal de contrôle)

### 2.4 Comparaison des codes

| Code | Distance de Shannon | Complexité | Usage |
|------|---------------------|------------|-------|
| Hamming | ~3 dB | Faible | Mémoire ECC |
| Reed-Solomon | ~2 dB | Moyenne | Stockage |
| Convolutif + Viterbi | ~1 dB | Moyenne | Espace |
| Turbo | ~0.5 dB | Élevée | 3G/4G |
| LDPC | ~0.1 dB | Élevée | 5G, WiFi |
| Polaire | 0 dB (théorique) | Moyenne | 5G |

---

## 3. Modulation et transmission

### 3.1 Modulation numérique

Convertit les bits en signaux physiques.

| Modulation | Principe | Bits/symbole | Robustesse |
|------------|----------|--------------|------------|
| **BPSK** | 2 phases | 1 | Très robuste |
| **QPSK** | 4 phases | 2 | Robuste |
| **8-PSK** | 8 phases | 3 | Moyenne |
| **16-QAM** | 16 points (amplitude + phase) | 4 | Moins robuste |
| **64-QAM** | 64 points | 6 | Sensible au bruit |
| **256-QAM** | 256 points | 8 | Très sensible |

### 3.2 OFDM (Orthogonal Frequency Division Multiplexing)

- Divise la bande en sous-porteuses orthogonales
- Chaque sous-porteuse utilise une modulation (QPSK, QAM)
- Résistant aux trajets multiples (multipath)
- Utilisé dans : WiFi, 4G/5G, DVB-T, ADSL

### 3.3 Multiplexage

| Technique | Principe | Exemple |
|-----------|----------|---------|
| **FDMA** | Fréquences différentes | Radio FM |
| **TDMA** | Slots temporels | GSM |
| **CDMA** | Codes orthogonaux | 3G |
| **OFDMA** | Sous-porteuses OFDM | 4G/5G |
| **MIMO** | Antennes multiples | WiFi, 5G |

---

## 4. Applications pratiques

### 4.1 Internet et réseaux

#### Protocoles de transport
- **TCP** : fiabilité par retransmission (ARQ)
- **UDP** : pas de correction, faible latence
- **QUIC** : UDP + correction d'erreurs intégrée

#### Compression HTTP
- **gzip** : DEFLATE standard
- **Brotli** : meilleure compression, moderne
- **Zstandard** : très rapide, bon ratio

### 4.2 Stockage

#### Disques et SSD
- **ECC** : codes correcteurs dans le contrôleur
- **RAID** : redondance entre disques
- **Scrubbing** : vérification périodique

#### Archivage
- **PAR2** : fichiers de parité pour archives
- **ZFS** : checksums + correction intégrés

### 4.3 Communications sans fil

#### WiFi (802.11)
- OFDM + LDPC + QAM adaptatif
- MIMO pour le débit
- Adaptation automatique au canal

#### 5G
- Codes polaires (contrôle) + LDPC (données)
- Massive MIMO
- Beamforming

### 4.4 Espace et satellites

- Codes convolutifs + Reed-Solomon (Voyager, Mars rovers)
- Turbo codes (missions récentes)
- Contraintes : puissance limitée, délai important

---

## 5. Compression neurale

### 5.1 Autoencodeurs

Architecture :
```
Entrée → Encodeur (compression) → Espace latent → Décodeur → Reconstruction
```

- **Bottleneck** : force la compression
- **Perte** : reconstruction + régularisation

### 5.2 Compression d'images par IA

- **Learned Image Compression** : surpasse JPEG, proche de H.265
- **Hyperpriors** : modélise la distribution latente
- **Attention** : focus sur les régions importantes

### 5.3 Codecs vidéo neuronaux

- Remplacement des blocs traditionnels par des réseaux
- Interpolation de frames par IA
- Super-résolution pour réduire le débit

---

## Conclusion

Le codage source et le codage canal sont les deux faces d'une même médaille :

1. **Compression** : élimine la redondance pour minimiser les bits
2. **Correction d'erreurs** : ajoute de la redondance contrôlée pour la fiabilité

Les théorèmes de Shannon établissent les limites fondamentales :
- On ne peut pas compresser sous l'entropie
- On peut transmettre sans erreur jusqu'à la capacité du canal

Ces principes, énoncés en 1948, guident encore aujourd'hui la conception des systèmes de communication modernes, de la 5G aux sondes spatiales.

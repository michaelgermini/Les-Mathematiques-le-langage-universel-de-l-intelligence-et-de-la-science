# 5.3. Optimisation continue

## Introduction : Trouver le meilleur dans un monde continu

L'optimisation continue cherche à trouver les valeurs optimales de fonctions dans des espaces continus. Cette discipline mathématique est au cœur de l'ingénierie, de l'économie et de l'apprentissage automatique, permettant de résoudre des problèmes allant de la conception de voitures à l'optimisation de portefeuilles financiers.

## Optimisation sans contraintes

### Condition du premier ordre

Pour f : ℝⁿ → ℝ différentiable :
∇f(x*) = 0 (gradient nul au point stationnaire)

- **Points critiques** : candidats à l'optimum
- **Classification** : minimum, maximum, point selle

### Condition du second ordre

Matrice hessienne H(x*) :
- **Définie positive** : minimum local
- **Définie négative** : maximum local
- **Indéfinie** : point selle

### Méthodes de descente

#### Descente de gradient
x_{k+1} = x_k - η ∇f(x_k)

- **Direction** : -∇f (plus raide descente)
- **Pas** : η constant ou adaptatif
- **Convergence** : vers minimum local

#### Méthode de Newton
x_{k+1} = x_k - H⁻¹ ∇f(x_k)

- **Quadratique locale** : approximation de second ordre
- **Convergence quadratique** : très rapide près de la solution
- **Coût** : inversion de la hessienne

#### Quasi-Newton (BFGS)
Approximation de H⁻¹ sans calcul explicite :
- **Mise à jour** : formule de rang 1 ou 2
- **Mémoire limitée** : L-BFGS pour gros problèmes
- **Efficacité** : bon compromis vitesse/précision

## Optimisation avec contraintes

### Méthode des multiplicateurs de Lagrange

#### Problème
min f(x) sous g(x) = 0

#### Lagrangien
L(x,λ) = f(x) + λ g(x)

#### Conditions KKT
∇L = 0 et g(x) = 0

### Inégalités et contraintes actives

#### Conditions KKT généralisées
Pour min f(x) sous g_i(x) ≤ 0 :
- ∇L = 0
- g_i ≤ 0, λ_i ≥ 0
- λ_i g_i = 0 (complémentarité)

### Méthodes de pénalisation

#### Fonction barrière
Transformation en problème sans contraintes :
min f(x) - (1/t) Σ log(-g_i(x))

#### Méthode des pénalités
min f(x) + ρ Σ [max(0, g_i(x))]²

## Programmation quadratique

### Problème standard
min (1/2) x* H x + c* x
sous A x ≤ b

### Solution analytique
- **QP duale** : formulation duale
- **Décomposition** : méthodes actives/ensembles
- **Applications** : SVM, optimisation de portefeuille

## Optimisation convexe

### Fonctions convexes

f convexe si ∀x,y, λ∈[0,1] :
f(λx + (1-λ)y) ≤ λ f(x) + (1-λ) f(y)

### Propriétés
- **Minimum global** : ensemble des minima convexe
- **Condition suffisante** : ∇f = 0 et H définie positive
- **Dualité** : problème primal/duel

### Méthodes
- **Gradient projeté** : projection sur le convexe
- **Méthodes proximales** : opérateurs prox
- **ADMM** : alternating direction method

## Optimisation stochastique

### Gradient stochastique
E[∇f(x; ξ)] = ∇f(x) pour bruit ξ

- **Mini-batch** : estimation sur sous-ensemble
- **Variance réduite** : SAG, SVRG
- **Applications** : apprentissage profond

### Optimisation bayésienne
- **Fonctions d'acquisition** : expected improvement
- **GP (Gaussian Processes)** : modèle de la fonction objectif
- **Applications** : hyperparamètres, conception expérimentale

## Applications pratiques

### Ingénierie

#### Conception optimale
- **Structures** : minimiser poids sous contraintes
- **Aérodynamique** : optimiser formes pour réduire traînée
- **Circuits** : dimensionnement optimal

#### Contrôle automatique
- **Régulateurs PID** : optimisation des paramètres
- **Commande optimale** : principe du maximum de Pontryagin
- **Filtrage** : Kalman optimal

### Économie et finance

#### Théorie du portefeuille
min σ² sous E[R] ≥ μ (Markowitz)

#### Pricing d'options
- **Black-Scholes** : équation aux dérivées partielles
- **Méthodes Monte-Carlo** : simulation de prix
- **Calibration** : ajustement aux données de marché

### Apprentissage automatique

#### Régression
- **Moindres carrés** : min ||y - Xβ||²
- **Ridge/Lasso** : régularisation L2/L1
- **Robustesse** : moindres carrés pondérés

#### Classification
- **SVM** : maximiser marge
- **Réseaux neuronaux** : descente de gradient stochastique
- **Boosting** : optimisation fonctionnelle

### Sciences

#### Imagerie médicale
- **Reconstruction** : tomographie par émissions
- **Segmentation** : optimisation de contours
- **Débruitage** : régularisation variationnelle

#### Biologie computationnelle
- **Alignement de séquences** : programmation dynamique
- **Phylogénie** : optimisation d'arbres
- **Modélisation** : paramètres de modèles

## Algorithmes évolutifs et heuristiques

### Algorithmes génétiques
- **Population** : ensemble de solutions candidates
- **Sélection** : survie des meilleurs
- **Croisement/mutation** : génération nouvelle
- **Applications** : problèmes NP-difficiles

### Recherche tabou
- **Mémoire** : éviter cycles dans la recherche
- **Liste tabou** : mouvements interdits temporairement
- **Diversification** : exploration de nouvelles régions

### Optimisation par essaims
- **Particules** : solutions avec vitesse
- **PSO** : particle swarm optimization
- **Inspiration** : comportement d'oiseaux/abeilles

## Défis modernes

### Optimisation à grande échelle
- **Problèmes distribués** : décomposition/coordination
- **Mémoire limitée** : sketchs et approximations
- **Calcul parallèle** : GPU, clusters

### Optimisation non-convexe
- **Paysage complexe** : multiples minima locaux
- **Théorie** : analyse des points critiques
- **Pratique** : initialisations multiples, continuation

### Apprentissage et optimisation
- **Meta-learning** : optimiser les optimiseurs
- **Apprentissage différentiable** : différentiation automatique
- **Optimisation neurale** : réseaux pour résoudre optimisation

## Conclusion : L'optimisation comme science de la décision

L'optimisation continue transforme les problèmes de décision en défis mathématiques rigoureux. Des moteurs de recherche aux voitures autonomes, elle permet de trouver automatiquement les meilleures solutions dans un monde complexe.

Dans l'ère de l'IA et du Big Data, l'optimisation devient le langage commun entre les données, les modèles et les décisions, ouvrant la voie à une prise de décision intelligente et efficace.


# 4.3. Valeurs propres et décomposition SVD

## Introduction : Décomposer pour comprendre

Les valeurs propres et la décomposition en valeurs singulières (SVD) constituent deux piliers de l'analyse matricielle. Ces outils permettent de décomposer des transformations complexes en éléments plus simples, révélant la structure profonde des données et ouvrant la voie à des applications révolutionnaires.

## Les valeurs propres : spectre d'une matrice

### Définition et interprétation

Pour une matrice carrée A, λ est valeur propre si ∃v ≠ 0 tel que :
Av = λv

- **Vecteur propre** : v, direction invariante
- **Valeur propre** : λ, facteur d'échelle
- **Sous-espace propre** : ensemble des vecteurs propres associés à λ

### Calcul pratique

#### Polynôme caractéristique
det(A - λI) = 0

- **Racines** : valeurs propres
- **Multiplicité algébrique** : ordre de la racine
- **Multiplicité géométrique** : dimension de l'espace propre

#### Méthode de puissance
Pour la valeur propre dominante :
- Itération : v_{k+1} = A v_k / ||A v_k||
- Convergence : vers le vecteur propre dominant
- Accélération : méthode de puissance avec décalage

### Classification des matrices

#### Matrices diagonalisables
- **Condition** : n vecteurs propres linéairement indépendants
- **Forme** : A = P D P⁻¹ avec D diagonale
- **Exemples** : matrices symétriques, matrices à coefficients distincts

#### Matrices non diagonalisables
- **Jordan** : blocs de Jordan pour chaînes généralisées
- **Nilpotentes** : puissances successives donnent zéro

## Théorème spectral et matrices symétriques

### Théorème spectral réel

Pour une matrice symétrique réelle A :
- **Valeurs propres réelles**
- **Vecteurs propres orthogonaux**
- **Base orthonormale** de vecteurs propres

### Démonstration géométrique

Considérons le produit scalaire ⟨Av, v⟩ :
- Pour v unitaire, c'est la moyenne pondérée des valeurs propres
- L'extremum est atteint dans la direction des vecteurs propres

### Applications en optimisation

- **Méthode des multiplicateurs de Lagrange**
- **Analyse convexe** : matrices semi-définies positives
- **Quadratiques** : formes quadratiques et extrema

## La décomposition en valeurs singulières (SVD)

### Définition fondamentale

Toute matrice m×n peut se décomposer en :
A = U Σ V*

Où :
- **U** : matrice unitaire m×m (colonnes : vecteurs singuliers gauches)
- **Σ** : matrice diagonale m×n avec valeurs singulières σ₁ ≥ σ₂ ≥ ... ≥ 0
- **V** : matrice unitaire n×n (colonnes : vecteurs singuliers droits)

### Interprétation géométrique

#### Transformation composée
A effectue trois transformations successives :
1. **Rotation/déformation** : V*
2. **Mise à l'échelle** : Σ (étirement selon les axes principaux)
3. **Rotation** : U

#### Ellipses et hyperboles
- **Image du cercle unité** : ellipse dont les demi-axes sont les valeurs singulières
- **Conditionnement** : rapport σ₁/σₖ mesure la "forme" de l'ellipse

### Propriétés remarquables

#### Valeurs singulières
σᵢ = √λᵢ où λᵢ valeurs propres de A*A ou A*A

- **Positives ou nulles**
- **Invariantes par transposition**
- **Liées aux normes** : ||A||₂ = σ₁ (plus grande valeur singulière)

#### Rang et approximation
- **Rang matriciel** : nombre de valeurs singulières non nulles
- **Approximation de rang k** : garder les k plus grandes valeurs singulières

## Applications de la SVD

### Compression de données

#### Images numériques
- **Décomposition SVD** : U Σ V* avec Σ diagonale
- **Compression** : garder seulement les k plus grandes valeurs singulières
- **Qualité** : erreur quadratique moyenne minimale pour un rang donné

#### Exemple concret
Une image 1000×1000 pixels :
- SVD complète : ~10^6 coefficients
- Rang 50 : ~50×10^3 coefficients (compression 95%)
- Qualité visuelle : souvent excellente

### Analyse en composantes principales (PCA)

#### Principe
- **Centrage des données** : matrice X des observations
- **SVD de X** : révèle les directions principales de variance
- **Composantes principales** : colonnes de V (vecteurs singuliers droits)

#### Algorithme
1. Calculer la matrice de covariance X*X
2. SVD : X*X = V Σ² V*
3. Les composantes principales sont les colonnes de V

### Systèmes de recommandation

#### Factorisation matricielle
- **Matrice utilisateur-item** : notes des utilisateurs sur les items
- **SVD** : décomposition en facteurs latents
- **Prédiction** : reconstruction partielle pour les valeurs manquantes

#### Netflix Prize
- **Défi historique** : améliorer les recommandations de 10%
- **Techniques SVD** : modèles factorisation matricielle
- **Impact** : révolution des systèmes de recommandation

### Traitement du signal et images

#### Débruitage
- **Bruit additif** : SVD révèle la structure sous-jacente
- **Seuil des valeurs singulières** : éliminer les petites valeurs (bruit)

#### Reconnaissance faciale
- **Eigenfaces** : PCA sur images de visages
- **Classification** : projection sur les composantes principales
- **Identification** : distance dans l'espace des caractéristiques

### Mécanique et physique

#### Analyse modale
- **Matrices de rigidité/masse** : systèmes dynamiques
- **Modes propres** : vecteurs propres (mouvements naturels)
- **Fréquences propres** : valeurs propres

#### Écoulement de fluides
- **POD (Proper Orthogonal Decomposition)** : SVD sur champs de vitesse
- **Modes dominants** : structures cohérentes du flot
- **Réduction de modèle** : simulation efficace

## Extensions et généralisations

### SVD généralisée

Pour matrices rectangulaires de tailles différentes :
- **GSVD** : généralisation aux matrices non carrées
- **Applications** : résolution de systèmes surdéterminés

### SVD en complexe

Matrices complexes :
- **Unitaires complexes** : U et V unitaires
- **Applications** : traitement du signal complexe, mécanique quantique

### Tenseurs et décompositions multi-linéaires

#### CPD (Canonical Polyadic Decomposition)
Décomposition de tenseurs en somme de produits :
A = Σᵣ uᵣ ⊗ vᵣ ⊗ wᵣ

#### Applications
- **Traitement d'images couleur** : tenseurs 3D
- **Analyse de réseaux** : graphes multi-partites

## Conclusion : La puissance de la décomposition

Les valeurs propres et la SVD offrent des outils puissants pour analyser et comprendre les structures linéaires cachées dans les données. De la compression d'images aux systèmes de recommandation, ces techniques mathématiques fondamentales sont au cœur des technologies modernes de l'information et de l'IA.


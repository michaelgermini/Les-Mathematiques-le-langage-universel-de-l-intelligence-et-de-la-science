# 16.2. Théorie de l’apprentissage

## Apprentissage statistique

### Théorie VC (Vapnik–Chervonenkis)
- **Dimension VC** : mesure de la complexité d’une classe d’hypothèses (nombre maximal de points pouvant être shatter).  
- **Structural Risk Minimization (SRM)** : compromis biais–variance par choix de modèles de complexité croissante.  
- **Bornes de généralisation** : garantissent que l’erreur sur les données de test est proche de l’erreur d’entraînement,
  avec une probabilité contrôlée, en fonction de la dimension VC et de la taille d’échantillon.

### Apprentissage PAC (Probably Approximately Correct)
- **ε‑approximation** : on cherche un modèle dont l’erreur vraie est < ε.  
- **δ‑confiance** : avec probabilité au moins 1 − δ.  
- **Taille d’échantillon** : dépend de la dimension VC, de ε et δ ; plus le modèle est complexe,
  plus il faut de données pour garantir une bonne généralisation.

Ces cadres donnent une base mathématique pour comprendre **pourquoi** et **quand** un algorithme d’apprentissage
peut espérer bien se comporter sur des données nouvelles.

## Théorie de l’optimisation en apprentissage

### Convergence des algorithmes
- **SGD** (Stochastic Gradient Descent) : taux O(1/√T) pour fonctions convexes lisses, O(1/T) pour strongly convex.  
- **Variance reduction** : méthodes comme SVRG, SAGA améliorent la convergence en réduisant la variance des gradients.  
- **Accélération** : schémas à la Nesterov, momentum, conduisent à des taux améliorés (O(1/T²) pour certaines classes).

### Analyse du paysage de perte
- **Loss landscapes** : géométrie de la fonction de perte dans l’espace des paramètres.  
- **Mode connectivity** : existence de chemins de faible perte entre minima apparents.  
- **Minima plats vs aigus** : les minima plats sont souvent associés à une meilleure généralisation.

## Apprentissage profond : questions théoriques

### Expressivité des réseaux
- **Théorème d’approximation universelle** : un réseau à une couche cachée peut approximer toute fonction continue
  sur un compact, sous certaines conditions.  
- **Profondeur vs largeur** : des réseaux profonds peuvent représenter certaines fonctions beaucoup plus
  efficacement que des réseaux peu profonds mais très larges.  
- **Neural Tangent Kernel (NTK)** : lien entre réseaux très larges et méthodes à noyaux.

### Généralisation en deep learning
- **Double descent** : comportement du risque qui décroît à nouveau après la sur‑paramétrisation.  
- **Régularisation implicite** : SGD et variantes semblent favoriser des solutions “simples” même sans pénalisation explicite.  
- **Inductive biases** : les architectures (CNN, Transformers, GNN) encodent des hypothèses structurelles (invariances, localité).

## Apprentissage par renforcement : aspects théoriques

### Processus de décision markoviens (MDP)
- **Optimalité** : équation de Bellman pour la valeur optimale V* et Q*.  
- **Convergence** : itération de valeur (value iteration) et itération de politique (policy iteration)
  convergent vers la solution optimale sous certaines conditions.  
- **Sample complexity** : nombre d’échantillons nécessaires pour apprendre une politique ε‑optimale.

### Exploration–Exploitation
- **Bandits multi‑bras** : compromis entre explorer de nouvelles actions et exploiter la meilleure connue.  
- **Thompson sampling** : stratégie bayésienne optimale dans divers contextes.  
- **UCB (Upper Confidence Bound)** : algorithmes avec bornes de regret prouvées.

## Meta‑apprentissage et few‑shot learning

### Meta‑learning
- **MAML** (Model‑Agnostic Meta‑Learning) : trouver une bonne initialisation de paramètres
  qui s’adapte rapidement à de nouvelles tâches.  
- **Prototypical networks** : classification few‑shot basée sur des centres de classes dans l’espace latent.  
- **Networks with memory** : architectures augmentées de mémoires différentiables (Neural Turing Machines).

### Transfer learning et multi‑tâches
- **Fine‑tuning** : adaptation de modèles pré‑entraînés (vision, langage) à de nouvelles tâches.  
- **Domain adaptation** : généralisation à de nouveaux domaines avec distributions différentes.  
- **Multi‑task learning** : apprentissage simultané de plusieurs tâches corrélées, partageant des représentations.

Ces développements montrent que la théorie de l’apprentissage ne se limite plus aux modèles simples :
elle s’étend progressivement aux architectures profondes, aux scénarios séquentiels et aux contextes
où les données sont rares ou non stationnaires.

# 16.3. Limites mathématiques de l’IA actuelle

## Limitations fondamentales

### Problèmes indécidables
- **Problème de l’arrêt** : aucun algorithme général ne peut décider, pour tout programme
  et toute entrée, s’il terminera ou tournera indéfiniment.  
- **Équivalence de programmes** : pas de test général pour savoir si deux programmes
  produisent toujours la même sortie.  
- **Apprentissage** : certaines formes d’induction sont fondamentalement impossibles
  (résultats de Gold, limites de la généralisation à partir de données finies).

### Théorèmes d’incomplétude (Gödel)
- **Incomplétude** : tout système formel assez riche (arithmétique de Peano) contient
  des énoncés vrais mais indémontrables dans ce système.  
- **Indécidabilité** : il n’existe pas de procédure mécanique pour trancher tous les énoncés.  
- **Conséquences** : limites intrinsèques de la vérification formelle complète des systèmes complexes.

## Limites computationnelles

### Complexité
- **P vs NP** : séparation inconnue entre problèmes “faciles” et “vérifiables rapidement”.  
- **NP‑complet** : classe de problèmes intrinsèquement difficiles (si l’un est en P, tous le sont).  
- **Approximation** : pour beaucoup de problèmes NP‑difficiles, seuls des algorithmes approchés
  avec garanties partielles sont envisageables.

### Ressources computationnelles
- **Efficacité énergétique** : coût environnemental de l’entraînement de grands modèles (CO₂, matériel).  
- **Mémoire** : limites de stockage et de bande passante (loi de von Neumann).  
- **Parallélisation** : loi d’Amdahl (une partie séquentielle borne le gain maximal du parallélisme).

## Limites de l’apprentissage automatique

### Biais et équité (fairness)
- **Biais dans les données** : l’IA hérite et amplifie les discriminations présentes dans les données.  
- **Fairness metrics** : tensions entre égalité démographique, égalité des odds, fairness individuelle.  
- **Inférence causale** : corrélation ≠ causalité ; sans modèle causal, corriger le biais est délicat.

### Robustesse et sécurité
- **Adversarial examples** : petites perturbations imperceptibles peuvent tromper des modèles puissants.  
- **Poisoning attacks** : contamination des données d’entraînement pour influencer le modèle.  
- **Model inversion / membership inference** : reconstruction ou détection d’informations privées.

### Généralisation et extrapolation
- **Domain shift** : chute de performance hors distribution d’entraînement (OOD).  
- **Détection OOD** : difficile à réaliser de manière fiable.  
- **Raisonnement causal** : l’IA statistique peine à extrapoler à des interventions ou des mondes contrefactuels.

## Limites cognitives

### Compréhension vs reconnaissance de patterns
- **Boîtes noires** : décisions non interprétables pour les humains.  
- **Corrélations fallacieuses** : modèles exploitant des artefacts sans rapport causal.  
- **Hallucinations** : génération de contenu faux mais plausible par les modèles de langage.

### Créativité et raisonnement
- **Recherche vs insight** : exploration aveugle d’un espace de solutions vs compréhension conceptuelle.  
- **Mathématiques créatives** : l’IA peut assister, mais la découverte de concepts profonds reste difficile à automatiser.  
- **Conscience et “agency”** : l’optimisation de fonctions de perte ne produit pas nécessairement
  des entités conscientes ou responsables.

## Perspectives et défis

### Vers l’AGI (Artificial General Intelligence)
- **Architectures hybrides** : combiner symbolique et connexionnisme (neurosymbolique).  
- **Apprentissage continu** : éviter le “catastrophic forgetting”.  
- **Multi‑modalité** : intégration cohérente de texte, image, son, action.

### Questions philosophiques
- **Conscience** : peut‑elle émerger d’un processus purement algorithmique ?  
- **Libre arbitre** : décisions déterministes vs notion de choix.  
- **Responsabilité** : qui répond des actions de systèmes autonomes (développeurs, opérateurs, IA) ?

### Recherche fondamentale
- **Neurosymbolique** : tentative d’unifier raisonnement logique et réseaux neuronaux.  
- **Energy‑based models** : cadre unificateur pour de nombreuses architectures.  
- **Causal ML** : apprentissage causal pour dépasser la simple corrélation.

Ces limites ne condamnent pas l’IA, mais rappellent que, même armée de mathématiques puissantes,
elle reste contrainte par des **barrières théoriques profondes**, et qu’il est essentiel
de les connaître pour l’utiliser de manière responsable.

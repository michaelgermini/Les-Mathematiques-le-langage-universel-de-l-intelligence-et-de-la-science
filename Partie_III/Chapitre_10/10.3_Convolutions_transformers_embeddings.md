# 10.3. Convolutions, transformers, embeddings

## Réseaux convolutifs (CNN)

### Convolution 1D
(y * k)[i] = Σ_j y[i+j] k[j]

- **Filtre (kernel)** : k de taille fixe
- **Stride** : pas de déplacement du filtre
- **Padding** : bordure pour conserver la taille

### Convolution 2D pour images
(I * K)[i,j] = Σ_m Σ_n I[i+m,j+n] K[m,n]

- **Feature maps** : cartes d'activation par filtre
- **Pooling** : réduction de dimension (max ou average)
- **Invariance** : translation, petites déformations

### Architectures CNN célèbres
- **LeNet-5** (1998) : reconnaissance de chiffres manuscrits
- **AlexNet** (2012) : breakthrough ImageNet
- **VGG** (2014) : profondeur uniforme, filtres 3×3
- **ResNet** (2015) : connexions résiduelles, très profond

## Transformers

### Mécanisme d'attention
Attention(Q,K,V) = softmax(QK^T / √d_k) V

- **Query (Q)** : ce qu'on cherche
- **Key (K)** : ce à quoi on compare
- **Value (V)** : ce qu'on retourne
- **Scaled dot-product** : division par √d_k pour stabilité

### Multi-head attention
- **Parallèle** : h têtes d'attention indépendantes
- **Concaténation** : fusion des sorties
- **Diversité** : capture différents aspects des données

### Architecture Transformer complète
- **Encoder** : compréhension bidirectionnelle du contexte
- **Decoder** : génération séquentielle autoregressive
- **Position encoding** : information de position (sinusoïdal ou appris)
- **Layer normalization** : normalisation par couche

## Embeddings

### Word embeddings
- **One-hot** : sparse, haute dimension, pas de similarité
- **Dense** : continue, basse dimension, capture la sémantique
- **Apprentissage** : pendant l'entraînement du modèle

### Word2Vec
- **CBOW** : prédire mot central depuis contexte
- **Skip-gram** : prédire contexte depuis mot central
- **Negative sampling** : approximation efficace de softmax

### Embeddings contextuels
- **ELMo** (2018) : bidirectionnel, représentations fixes
- **BERT** (2018) : bidirectionnel, pré-entraînement masqué
- **GPT** (2018+) : unidirectionnel, génératif

## Applications avancées

### Vision par ordinateur
- **Object detection** : YOLO, Faster R-CNN
- **Segmentation** : U-Net, Mask R-CNN
- **Vision Transformers** : ViT, CLIP

### Traitement du langage naturel
- **Classification** : sentiment analysis
- **Traduction** : seq2seq avec attention
- **Question answering** : SQuAD, GLUE benchmarks

### Multimodal
- **CLIP** : alignement image-texte
- **DALL-E** : génération d'images depuis texte
- **Flamingo** : vision-language models

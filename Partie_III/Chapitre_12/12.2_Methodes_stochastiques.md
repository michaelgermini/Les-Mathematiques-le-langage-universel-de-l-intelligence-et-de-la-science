# 12.2. Méthodes stochastiques

## Gradient stochastique (SGD)

### SGD de base
θ_{t+1} = θ_t - η_t ∇L(θ_t; ξ_t)

- **Estimation** : gradient sur un échantillon aléatoire ξ_t
- **Espérance** : E[∇L(θ; ξ)] = ∇L(θ) (estimateur non biaisé)
- **Variance** : bruit utile pour échapper aux minima locaux
- **Convergence** : O(1/√T) pour fonctions convexes

### Mini-batch SGD
- **Batch** : moyenne sur k échantillons
- **Réduction variance** : par facteur 1/k
- **Compromis** : taille batch vs vitesse de convergence

## Réduction de variance

### SAGA
g_t = ∇f_i(θ_t) - ∇f_i(θ_i^{old}) + (1/n) Σ_j ∇f_j(θ_j^{old})

- **Correction** : par différence avec gradient stocké
- **Mémoire** : stockage de n gradients
- **Convergence** : linéaire pour strongly convex

### SVRG (Stochastic Variance Reduced Gradient)
- **Référence périodique** : gradient complet calculé périodiquement
- **Correction** : par rapport à la référence
- **Convergence** : linéaire sans stockage permanent

## Méthodes proximales

### Opérateur proximal
prox_{γf}(x) = argmin_y [f(y) + (1/(2γ))||y - x||²]

- **Forme fermée** : pour fonctions simples (L1, indicatrices)
- **Composition** : proximal d'une somme via splitting

### Proximal gradient descent
x_{k+1} = prox_{η g} (x_k - η ∇f(x_k))

- **Structure** : f différentiable, g prox-friendly
- **ISTA** : Iterative Shrinkage-Thresholding Algorithm
- **FISTA** : version accélérée (Nesterov)

## Méthodes quasi-Newton stochastiques

### L-BFGS stochastique
- **Approximation** : de l'inverse de la hessienne
- **Mémoire limitée** : stockage O(md) pour m paires
- **Stochastique** : avec mini-batch et corrections

### Natural gradient
- **Métrique de Fisher** : F = E[∇log p · ∇log p^T]
- **Direction** : F^{-1} ∇L (préconditionnement naturel)
- **Applications** : RL, meta-learning

## Optimisation distribuée

### Consensus optimization
- **Problème** : min Σ_i f_i(x) avec données distribuées
- **Consensus** : variables locales convergent vers globale
- **ADMM** : Alternating Direction Method of Multipliers

### Federated learning
- **Données distribuées** : privacy-preserving
- **FedAvg** : moyenne des modèles locaux
- **Hétérogénéité** : données non-IID entre clients

## Applications modernes

### Deep learning
- **Grande échelle** : milliards de paramètres
- **GPU/TPU** : parallélisation massive
- **Mixed precision** : FP16 + FP32 pour efficacité

### Reinforcement learning
- **Policy gradient** : REINFORCE, PPO
- **Actor-critic** : estimation de l'avantage
- **Off-policy** : importance sampling
